{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to calibrate lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_lambda = 0.7\n",
    "dataset = 'utkface'\n",
    "method = 'fairPATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the losses\n",
    "loss_dir = f\"../previous_results/loss_functions/{dataset}/{method}\"\n",
    "loss_builder_acc = np.load(loss_dir+'/builder_loss_acc.npy')  \n",
    "if method == 'fairPATE':\n",
    "    loss_builder_cov = np.load(loss_dir+'/builder_loss_cov.npy')\n",
    "loss_privacy = np.load(loss_dir+'/privacy_loss.npy')\n",
    "loss_fairness = np.load(loss_dir+'/fairness_loss.npy')\n",
    "priv_fair_values = np.load(loss_dir+'/priv_fair_values.npy')\n",
    "\n",
    "priv_values = priv_fair_values[:,0]\n",
    "fair_values = priv_fair_values[:,1]\n",
    "if method == 'fairPATE':\n",
    "    losses = np.squeeze(np.stack((-1 * loss_builder_acc, loss_privacy, loss_fairness, -1 * loss_builder_cov), axis=-1))\n",
    "else:\n",
    "    losses = np.squeeze(np.stack((-1 * loss_builder_acc, loss_privacy, loss_fairness), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pareto_efficient(costs, return_mask = False):\n",
    "    \"\"\"\n",
    "        Find the pareto-efficient points\n",
    "        :param costs: An (n_points, n_costs) array\n",
    "        :param return_mask: True to return a mask\n",
    "        :return: An array of indices of pareto-efficient points.\n",
    "            If return_mask is True, this will be an (n_points, ) boolean array\n",
    "            Otherwise it will be a (n_efficient_points, ) integer array of indices.\n",
    "    \"\"\"\n",
    "    is_efficient = np.arange(costs.shape[0])\n",
    "    n_points = costs.shape[0]\n",
    "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
    "    while next_point_index<len(costs):\n",
    "        nondominated_point_mask = np.any(costs<costs[next_point_index], axis=1)\n",
    "        nondominated_point_mask[next_point_index] = True\n",
    "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "        costs = costs[nondominated_point_mask]\n",
    "        next_point_index = np.sum(nondominated_point_mask[:next_point_index])+1\n",
    "    if return_mask:\n",
    "        is_efficient_mask = np.zeros(n_points, dtype = bool)\n",
    "        is_efficient_mask[is_efficient] = True\n",
    "        return is_efficient_mask\n",
    "    else:\n",
    "        return is_efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pf(losses, priv_values, fair_values):\n",
    "    # select points on the PF\n",
    "    pf_indices = is_pareto_efficient(losses)\n",
    "    pf_losses = losses[pf_indices, :]\n",
    "    pf_priv = priv_values[pf_indices]\n",
    "    pf_fair = fair_values[pf_indices]\n",
    "    \n",
    "    return pf_losses, pf_priv, pf_fair, pf_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate to get surface\n",
    "def interpolate_losses(losses, priv_values, fair_values):\n",
    "    '''\n",
    "        Interpolate the losses into a grid format\n",
    "        :param priv_values: epsilon of points\n",
    "        :param fair_values: gamma of points\n",
    "        :param loss: loss value specific to each agent\n",
    "    '''\n",
    "    x = priv_values\n",
    "    y = fair_values\n",
    "    xi = np.linspace(x.min(), x.max(), 50)\n",
    "    yi = np.linspace(y.min(), y.max(), 50)\n",
    "    X,Y = np.meshgrid(xi,yi)\n",
    "    losses_inter = griddata((x,y),losses,(X,Y), method='linear')\n",
    "    \n",
    "    return losses_inter, xi, yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get points on pf\n",
    "pf_losses, pf_priv, pf_fair, pf_indices = get_pf(losses, priv_values, fair_values)\n",
    "loss_privacy = pf_losses[:, 1]\n",
    "loss_fairness = pf_losses[:, 2]\n",
    "loss_builder_weighted = builder_lambda *0.01 * pf_losses[:, 0] + (1-builder_lambda) * pf_losses[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: using gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_loss_b, pi, fi = interpolate_losses(loss_builder_weighted, loss_privacy, loss_fairness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi[1] - fi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient\n",
    "grad_builder = np.gradient(interpolated_loss_b, fi[1] - fi[0], pi[1] - pi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate lambda_priv\n",
    "grad_priv = grad_builder[1]\n",
    "masked_priv = np.ma.masked_array(grad_priv, np.isnan(grad_priv))\n",
    "# calculate your weighted average here instead\n",
    "average = np.ma.average(masked_priv, axis=1)\n",
    "# this gives you the result\n",
    "lambda_priv = average.filled(np.nan)\n",
    "lambda_priv = -np.average(lambda_priv[~np.isnan(lambda_priv)])\n",
    "\n",
    "# calculate lambda_fair\n",
    "grad_fair = grad_builder[0]\n",
    "masked_fair = np.ma.masked_array(grad_fair, np.isnan(grad_fair))\n",
    "# calculate your weighted average here instead\n",
    "average = np.ma.average(masked_fair, axis=1)\n",
    "# this gives you the result\n",
    "lambda_fair = average.filled(np.nan)\n",
    "lambda_fair = -np.average(lambda_fair[~np.isnan(lambda_fair)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_priv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: using q-cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_cut = pd.qcut(loss_fairness, 20, labels=False)\n",
    "priv_cut = pd.qcut(loss_privacy, 12, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_priv = []\n",
    "for i in range(10):\n",
    "    # for each bin, select all points within\n",
    "    temp_build = loss_builder_weighted[fair_cut == i]\n",
    "    temp_priv = loss_privacy[fair_cut == i]\n",
    "    values = []\n",
    "    # calculate all pairs\n",
    "    for j in range(len(temp_build)-1):\n",
    "        temp_lambda = (temp_build-temp_build[j])/(temp_priv[j] - temp_priv)\n",
    "        values = values + list(temp_lambda[j+1:][temp_lambda[j+1:] != -math.inf])\n",
    "    lambdas_priv.append(sum(values)/len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lambdas_priv)/len(lambdas_priv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_fair = []\n",
    "for i in range(10):\n",
    "    # for each bin, select all points within\n",
    "    temp_build = loss_builder_weighted[priv_cut == i]\n",
    "    temp_fair = loss_fairness[priv_cut == i]\n",
    "    values = []\n",
    "    # calculate all pairs\n",
    "    for j in range(len(temp_build)-1):\n",
    "        temp_lambda = (temp_build-temp_build[j])/(temp_fair[j] - temp_fair)\n",
    "        values = values + list(temp_lambda[j+1:][temp_lambda[j+1:] != -math.inf])\n",
    "    lambdas_fair.append(sum(values)/len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lambdas_fair)/len(lambdas_fair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
